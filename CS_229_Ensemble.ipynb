{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ea2964-e495-4f03-ba03-0ee6a04c4d1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac07891b-8f60-4b77-af22-05a9f804c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "col_pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e634dec-b48b-42ed-b7ad-b224cdc158da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/hemanthhariharan/CS_229_Project/main/T1.csv')\n",
    "\n",
    "df['Date/Time'] = pd.to_datetime(df['Date/Time'], format = \"%d %m %Y %H:%M\", errors = \"coerce\")\n",
    "\n",
    "df = df.set_index('Date/Time')\n",
    "\n",
    "# Creating time-series features\n",
    "\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week'] = df.index.day_of_week\n",
    "\n",
    "df_normalized = (df - df.mean())/ df.std()\n",
    "\n",
    "mean_target = df['Theoretical_Power_Curve (KWh)'].mean()\n",
    "\n",
    "std_target = df['Theoretical_Power_Curve (KWh)'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4f55548-402d-45e9-b984-f129af64c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_normalized.loc[df.index < '2018-12-01'] # train on 11 months\n",
    "test = df_normalized.loc[df.index >= '2018-12-01'] # test on 1 month\n",
    "\n",
    "features = ['LV ActivePower (kW)', 'Wind Speed (m/s)', 'Wind Direction (Â°)', 'hour', 'day_of_week']\n",
    "target = ['Theoretical_Power_Curve (KWh)']\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d056ec86-13e2-4440-81e5-6553fcb4dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "# epoch = 15\n",
    "# neurons = 10\n",
    "# predict_values = 1000\n",
    "# lag = 24\n",
    "\n",
    "# X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7b781-c5ed-4fe3-9574-ed4f7de728c2",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d0b4006-bdad-431f-aeaa-15b9ab42bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 200\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "dropout = .05\n",
    "\n",
    "X_train_lstm = X_train.to_numpy()\n",
    "\n",
    "X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], 1, X_train_lstm.shape[1])\n",
    "\n",
    "# lstm_model = Sequential()\n",
    "# lstm_model.add(LSTM(units=neurons, dropout=dropout, activation='relu', batch_input_shape=(batch_size, X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "# lstm_model.add(Dense(1))  # Output layer for regression tasks\n",
    "# lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "# lstm_model.summary()\n",
    "\n",
    "lstm_model = LSTM(units=neurons, dropout=dropout, activation='relu', batch_input_shape=(batch_size, X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
    "# lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1a309-af85-4d56-873e-a875558a28d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4f07c15-a65d-4bae-bbbd-3201eda7d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbreg = xgb.XGBRegressor(n_estimators=1000, early_stopping_rounds=100, learning_rate=0.01, max_depth=5, reg_lambda=1)\n",
    "\n",
    "# xgbmodel = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05429036-7ab9-448d-8ed3-1b2ffe62b803",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3473cb-4c94-4fb4-92bb-6b8c352b4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        neurons = 200\n",
    "        batch_size = 100\n",
    "        epochs = 50\n",
    "        dropout = .05\n",
    "        # Add LSTM layers and other necessary layers\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.add(LSTM(units=neurons, dropout=dropout, activation='relu', batch_input_shape=(batch_size, X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "        self.add(Dense(1))  # Output layer for regression tasks\n",
    "        self.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "        # Implement your fit logic here\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Implement your prediction logic here\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373dec5-335a-41b5-ba69-9a19fc63b2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af3f6521-146f-428d-82ca-a7a1381cf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator_list =  [('lr', LinearRegression()), ('lstm', lstm_model), ('xgb', xgbreg)]\n",
    "\n",
    "estimator_list =  [('lr', LinearRegression()), ('logreg', LogisticRegression())]\n",
    "\n",
    "ensemble = StackingRegressor(estimators = estimator_list, final_estimator=LogisticRegression())\n",
    "\n",
    "# ensemble = StackingClassifier(estimators = \n",
    "#                               [('lstm', lstm_model)]\n",
    "#                              )\n",
    "\n",
    "# ensemble = StackingRegressor(estimators = \n",
    "#                               [('lr', LinearRegression()),\n",
    "#                                ('xgb', xgbreg)],\n",
    "#                               final_estimator=LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "81b38236-738b-4ae5-9b12-5da7ff9e2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:955: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator LogisticRegression should be a regressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mensemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:956\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;03m    Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    955\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:191\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mself : object\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# all_estimators contains all estimators, the one to be fitted and the\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# 'drop' string.\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m names, all_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_final_estimator()\n\u001b[1;32m    194\u001b[0m stack_method \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_estimators)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/ensemble/_base.py:282\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    284\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m    285\u001b[0m             )\n\u001b[1;32m    286\u001b[0m         )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[0;31mValueError\u001b[0m: The estimator LogisticRegression should be a regressor."
     ]
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe80411-d2c0-407e-ae1a-c187c449df8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
